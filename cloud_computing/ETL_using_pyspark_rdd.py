# -*- coding: utf-8 -*-
"""phase_1 using Pyspark RDD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Scl8j9bWG-Pr3B2wR_Bkr041FCUGW4BN
"""

pip install pyspark

pip install pyspark zstandard

import os
import re
import zstandard as zstd
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, StringType, StructField, StructType

spark = SparkSession.builder.appName("ChessDataCollection").getOrCreate()

# Path to your directory with PGN files
data_dir = '/content/'

# Function to decompress .zst file
def decompress_zst(file_path, output_path):
    with open(file_path, 'rb') as compressed:
        dctx = zstd.ZstdDecompressor()
        with open(output_path, 'wb') as decompressed:
            dctx.copy_stream(compressed, decompressed)

# Function to parse a single game from PGN format
def parse_game(pgn):
    headers = re.findall(r'\[([A-Za-z]+) "([^"]+)"\]', pgn)
    header_dict = {header[0]: header[1] for header in headers}
    result = header_dict.get("Result", "unknown")
    result_code = 0 if result == "1/2-1/2" else 1 if result == "1-0" else -1 if result == "0-1" else None

    # Check if WhiteElo and BlackElo are valid integers
    white_elo_str = header_dict.get("WhiteElo", "0")
    white_elo = int(white_elo_str) if white_elo_str.isdigit() else None

    black_elo_str = header_dict.get("BlackElo", "0")
    black_elo = int(black_elo_str) if black_elo_str.isdigit() else None

    time_control = header_dict.get("TimeControl", "unknown")
    return (white_elo, black_elo, time_control, result_code)

# Function to parse PGN file
def parse_pgn(file_path):
    with open(file_path, 'r') as file:
        data = file.read()
    games = re.split(r'\n\n', data)
    return [parse_game(game) for game in games if parse_game(game)]

# List all .zst files in the directory
all_zst_files = [os.path.join(data_dir, file_name) for file_name in os.listdir(data_dir) if file_name.endswith('.pgn.zst')]

# Decompress all .zst files and create a list of decompressed file paths
decompressed_files = []
for zst_file in all_zst_files:
    decompressed_file_path = zst_file.replace('.zst', '')
    decompress_zst(zst_file, decompressed_file_path)
    decompressed_files.append(decompressed_file_path)

# Read and parse all decompressed PGN files into an RDD
all_rows_rdd = spark.sparkContext.parallelize(decompressed_files).flatMap(parse_pgn).filter(lambda x: x is not None)

# Define the schema for the DataFrame
schema = StructType([
    StructField("white_rating", IntegerType(), True),
    StructField("black_rating", IntegerType(), True),
    StructField("time_control", StringType(), True),
    StructField("result", IntegerType(), True)
])

# Convert RDD to DataFrame
df = spark.createDataFrame(all_rows_rdd, schema=schema)
df.show(5)
# Write DataFrame to Parquet file
df.write.parquet('chessgames.parquet')

# Stop Spark session
spark.stop()